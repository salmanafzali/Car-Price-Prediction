{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "05312f5a",
   "metadata": {},
   "source": [
    "# Import All librarys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "785a3ade",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'Python 3.13.5' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from pandas.plotting import scatter_matrix\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder, OrdinalEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from xgboost import XGBRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb587c78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read file\n",
    "cars = pd.read_csv(\"D:\\Code File\\Project\\Car_F_and_P\\Car F and P.csv\")\n",
    "# for preprocessing and machin learning\n",
    "train, test = train_test_split(cars, test_size=0.2, random_state=3)\n",
    "# for general view\n",
    "cars_view = cars.copy()\n",
    "\n",
    "cars.shape, train.shape, test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30e1a620",
   "metadata": {},
   "outputs": [],
   "source": [
    "cars_view.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98b43292",
   "metadata": {},
   "outputs": [],
   "source": [
    "cars.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a17c06c",
   "metadata": {},
   "outputs": [],
   "source": [
    "cars_view.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1402967f",
   "metadata": {},
   "outputs": [],
   "source": [
    "cars_view.hist(bins=50, figsize=(10,7))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "687f5a05",
   "metadata": {},
   "outputs": [],
   "source": [
    "cars_view[\"Make\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "526d4399",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To understand the number of values\n",
    "cars_view[\"Engine Fuel Type\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b5cf939",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To understand the number of values\n",
    "cars_view[\"Vehicle Size\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41af43f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To understand the number of UNKNOWN\n",
    "cars_view[\"Transmission Type\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebccf19c",
   "metadata": {},
   "source": [
    "# Object missing fix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b39c1f16",
   "metadata": {},
   "source": [
    "# Fix Unknown value in Transmision Type column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae40c27f",
   "metadata": {},
   "outputs": [],
   "source": [
    "cars_view[cars_view[\"Transmission Type\"] == \"UNKNOWN\"].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff333916",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the average of the unknown number over the year for unknown fix\n",
    "cars_view[cars_view[\"Year\"] > 2000][\"Transmission Type\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08a2febc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fix unknown value in Transmission Type\n",
    "transmision_for = cars_view[\"Transmission Type\"].copy()\n",
    "year = cars_view[\"Year\"].copy()\n",
    "transmision_type = []               # new values\n",
    "cars_view = cars_view.drop(\"Transmission Type\", axis=1)\n",
    "\n",
    "number_ix = 0   # index numbers\n",
    "for i in transmision_for:\n",
    "    # because average of the unknown number over the year\n",
    "    if transmision_for[number_ix] == \"UNKNOWN\" and year[number_ix] <= 2000:\n",
    "        transmision_type.append(\"MANUAL\")\n",
    "        \n",
    "    elif transmision_for[number_ix] == \"UNKNOWN\" and year[number_ix] > 2000:\n",
    "        transmision_type.append(\"AUTOMATIC\")\n",
    "        \n",
    "    else:\n",
    "        transmision_type.append(i)\n",
    "        \n",
    "    number_ix += 1\n",
    "\n",
    "# Merge Columns\n",
    "cars_view.insert(6, \"Transmission Type\", transmision_type)\n",
    "cars_view.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fec4e532",
   "metadata": {},
   "outputs": [],
   "source": [
    "cars_view[\"Transmission Type\"].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cf572dd",
   "metadata": {},
   "source": [
    "# Fix Missing value in Engin Fuel Type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d2f1c6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# view models car\n",
    "cars_view[cars_view[\"Engine Fuel Type\"].isnull() == True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2fa7d1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fix missing value\n",
    "cars_view[\"Engine Fuel Type\"].fillna(\"regular unleaded\", inplace=True)\n",
    "\n",
    "cars_view.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92161ddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "cars_view[cars_view[\"Model\"] == \"Verona\"].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee198de5",
   "metadata": {},
   "source": [
    "# encode object value\n",
    "(encode object value for better view and better implementation for preprocessing and machin learning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c83b6a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ordinal encoder (Because the label encoder cannot be referenced in the pipeline madule)\n",
    "encoder = OrdinalEncoder(handle_unknown='error')\n",
    "feature = [\"Make\", \"Engine Fuel Type\", \"Transmission Type\", \"Driven_Wheels\", \"Vehicle Size\", \"Vehicle Style\"]\n",
    "\n",
    "encode_tmp = encoder.fit_transform(cars_view[feature])\n",
    "cars_view_encode = pd.DataFrame(encode_tmp, columns=feature)\n",
    "\n",
    "cars_view = cars_view.drop(feature, axis=1)\n",
    "end_columns = cars_view[[\"highway MPG\", \"city mpg\", \"Popularity\", \"MSRP\"]].copy()\n",
    "cars_view = cars_view.drop([\"highway MPG\", \"city mpg\", \"Popularity\", \"MSRP\"], axis=1)\n",
    "\n",
    "cars_view = pd.concat([cars_view, cars_view_encode, end_columns], axis=1)\n",
    "cars_view.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cc576b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "cars_view.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f24c8ad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "correlations = cars_view.drop([\"Model\", \"Market Category\"], axis=1).corr()\n",
    "correlations[\"MSRP\"].sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d014494d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# show other corrilation over the MSRP\n",
    "feature = [\"Driven_Wheels\", \"Popularity\", \"Number of Doors\", \"city mpg\", \"Transmission Type\", \"Engine HP\", \"MSRP\"]\n",
    "scatter_matrix(cars_view[feature], figsize=(10,8))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2def240d",
   "metadata": {},
   "outputs": [],
   "source": [
    "cars_view.plot(kind='scatter', x=\"MSRP\", y=\"Engine HP\", figsize=(10,7), alpha=0.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09387f12",
   "metadata": {},
   "outputs": [],
   "source": [
    "cars[cars_view[\"Engine HP\"] > 800]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9be54b2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "cars[cars_view[\"MSRP\"] > 1000000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d343fdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show ratio of columns with blank values to the remaining columns\n",
    "feature = [\"Year\", \"Engine HP\", \"Engine Cylinders\", \"Number of Doors\", \"Popularity\", \"Engine Fuel Type\"]\n",
    "scatter_matrix(cars_view[feature], figsize=(10,7))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd74f45e",
   "metadata": {},
   "outputs": [],
   "source": [
    "cars_view.plot(kind='scatter', x=\"Engine HP\", y=\"Year\", figsize=(10,7))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab527551",
   "metadata": {},
   "source": [
    "# Preprocessing\n",
    "1. Removing model and Market Category column because to high number of objects\n",
    "2. missing value in Engine Fuel Type, Engine HP, Engine Cylinders, Number of Doors, Transmission Type\n",
    "\n",
    "### Tip\n",
    "Presence of unknown in Transmission Type"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97dc07f6",
   "metadata": {},
   "source": [
    "# Pre Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ebf53f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pre processing \n",
    "df = train.copy()\n",
    "\n",
    "# label column set rows on other column\n",
    "df_y_upp = df[df[\"Year\"] >= 2010].copy()\n",
    "df_y_low = df[df[\"Year\"] < 2010].copy()\n",
    "df_y = pd.concat([df_y_upp, df_y_low], axis=0)\n",
    "df_y.reset_index(drop=True, inplace=True)\n",
    "df_y = df_y[\"MSRP\"].copy()\n",
    "\n",
    "df.drop(\"MSRP\", axis=1, inplace=True)\n",
    "\n",
    "# Extracting numeric values from a string\n",
    "df_num = df[[\"Year\", \"Engine HP\", \"Engine Cylinders\", \"Number of Doors\", \"highway MPG\", \"city mpg\", \"Popularity\"]].copy()\n",
    "\n",
    "df_cat = df[[\"Year\", \"Engine Fuel Type\", \"Transmission Type\", \"Driven_Wheels\", \"Vehicle Size\", \"Vehicle Style\"]].copy()\n",
    "\n",
    "# Engine HP missing value fix over year\n",
    "imputer = SimpleImputer(missing_values=np.nan, strategy='median')  \n",
    " \n",
    "df_hp_imputed_upp = imputer.fit_transform(df_num[df_num[\"Year\"] >= 2010][[\"Engine HP\"]])\n",
    "df_hp_imputed_upp = pd.DataFrame(df_hp_imputed_upp)\n",
    "df_hp_imputed_low = imputer.fit_transform(df_num[df_num[\"Year\"] < 2010][[\"Engine HP\"]])\n",
    "df_hp_imputed_low = pd.DataFrame(df_hp_imputed_low)\n",
    "df_hp_imputed = pd.concat([df_hp_imputed_upp, df_hp_imputed_low], axis=0)\n",
    "df_hp_imputed.reset_index(drop=True, inplace=True)\n",
    "df_hp_imputed.columns = [\"Engine HP\"]\n",
    "\n",
    "# set all rows in Engin HP\n",
    "df_num_upp = df_num[df_num['Year'] >= 2010].copy()\n",
    "df_num_low = df_num[df_num['Year'] < 2010].copy()\n",
    "df_num = pd.concat([df_num_upp, df_num_low], axis=0)\n",
    "df_num.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# concatinate Engin Hp to numeric values\n",
    "df_num.drop(\"Engine HP\", axis=1, inplace=True)\n",
    "df_num = pd.concat([df_num, df_hp_imputed], axis=1)\n",
    "\n",
    "# missing fix all numeric\n",
    "df_imputed = pd.DataFrame(imputer.fit_transform(df_num), columns=df_num.columns)\n",
    "\n",
    "# category fix\n",
    "# fix rows to numerical values\n",
    "df_cat_upp = df_cat[df_cat[\"Year\"] >= 2010].copy()\n",
    "df_cat_low = df_cat[df_cat[\"Year\"] < 2010].copy()\n",
    "df_cat = pd.concat([df_cat_upp, df_cat_low], axis=0)\n",
    "df_cat.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# new columns value fix\n",
    "new_transmision = []\n",
    "new_fuel = []\n",
    "\n",
    "# fix Transmission Unknown Value\n",
    "for t, y in zip(df_cat[\"Transmission Type\"], df_cat[\"Year\"]):\n",
    "    if t == \"UNKNOWN\":\n",
    "        if y >= 2000:\n",
    "            new_transmision.append(\"AUTOMATIC\")\n",
    "        else:\n",
    "            new_transmision.append(\"MANUAL\")\n",
    "    else:\n",
    "        new_transmision.append(t)\n",
    "    \n",
    "# fix missing value in Engin Fuel Type    \n",
    "for f in df_cat[\"Engine Fuel Type\"]:\n",
    "    if pd.isnull(f):\n",
    "        new_fuel.append(\"regular unleaded\")\n",
    "    else:\n",
    "        new_fuel.append(f)\n",
    "        \n",
    "        \n",
    "df_cat.drop(\"Year\", axis=1, inplace=True)\n",
    "\n",
    "# add Transmission column value fix\n",
    "df_cat.drop(\"Transmission Type\", axis=1, inplace=True)\n",
    "df_cat.insert(2, \"Transmission Type\", new_transmision)\n",
    "\n",
    "# add Engine Fuel Type column value fix\n",
    "df_cat.drop(\"Engine Fuel Type\", axis=1, inplace=True)\n",
    "df_cat.insert(1, \"Engine Fuel Type\", new_fuel)\n",
    "\n",
    "# encode object value \n",
    "encoder = OrdinalEncoder(handle_unknown='error')\n",
    "df_encode = pd.DataFrame(encoder.fit_transform(df_cat), columns=df_cat.columns)\n",
    "\n",
    "# concat numeric value and category value\n",
    "df_prepared = pd.concat([df_imputed, df_encode], axis=1)\n",
    "\n",
    "# standard scaler\n",
    "scaler = StandardScaler()\n",
    "df_prepared = pd.DataFrame(scaler.fit_transform(df_prepared), columns=df_prepared.columns)\n",
    "df_prepared.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "699d8101",
   "metadata": {},
   "source": [
    "# Pre Processing With Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "422a5334",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Attribute Selectortegy\n",
    "class AttributeSelector(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, attributes):\n",
    "        self.attr_name = attributes\n",
    "        \n",
    "    def fit(self, df):\n",
    "        return self\n",
    "    \n",
    "    # return values for next process in pipeline\n",
    "    def transform(self, df):\n",
    "        return df[self.attr_name].values\n",
    "\n",
    "# hourse power missing value fix over year\n",
    "class EnginHpFix(BaseEstimator, TransformerMixin):\n",
    "    def fit(self, df):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, df):\n",
    "        year_ix, hp_ix = 0, 1        # Engine HP missing value fix over year\n",
    "        df = pd.DataFrame(df)\n",
    "        imputer = SimpleImputer(missing_values=np.nan, strategy='median')  \n",
    "        \n",
    "        df_hp_imputed_upp = imputer.fit_transform(df[df[year_ix] >= 2010][[hp_ix]])\n",
    "        df_hp_imputed_upp = pd.DataFrame(df_hp_imputed_upp)\n",
    "        df_hp_imputed_low = imputer.fit_transform(df[df[year_ix] < 2010][[hp_ix]])\n",
    "        df_hp_imputed_low = pd.DataFrame(df_hp_imputed_low)\n",
    "        df_hp_imputed = pd.concat([df_hp_imputed_upp, df_hp_imputed_low], axis=0)\n",
    "        df_hp_imputed.reset_index(drop=True, inplace=True)\n",
    "\n",
    "        # set all rows in Engin HP\n",
    "        df_num_upp = df[df[year_ix] >= 2010].copy()\n",
    "        df_num_low = df[df[year_ix] < 2010].copy()\n",
    "        df_num = pd.concat([df_num_upp, df_num_low], axis=0)\n",
    "        df_num.reset_index(drop=True, inplace=True)\n",
    "\n",
    "        # concatinate Engin Hp to numeric values\n",
    "        df_num.drop(hp_ix, axis=1, inplace=True)\n",
    "        df_num = pd.concat([df_num, df_hp_imputed], axis=1)\n",
    "        \n",
    "        return df_num.values\n",
    "    \n",
    "# Category value fix\n",
    "class CategoryValueFix(BaseEstimator, TransformerMixin):\n",
    "    def fit(self, df):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, df):\n",
    "        year_ix, fuel_ix, trans_ix = 0, 1, 2     # index column number\n",
    "        \n",
    "        # set rows in numeric values\n",
    "        df = pd.DataFrame(df)\n",
    "\n",
    "        # save fix value\n",
    "        new_transmision = []\n",
    "        new_fuel = []\n",
    "        \n",
    "        # fix Transmission Unknown Value\n",
    "        for t, y in zip(df[trans_ix], df[year_ix]):\n",
    "            if t == \"UNKNOWN\":\n",
    "                if y >= 2000:\n",
    "                    new_transmision.append(\"AUTOMATIC\")\n",
    "                else:\n",
    "                    new_transmision.append(\"MANUAL\")\n",
    "            else:\n",
    "                new_transmision.append(t)\n",
    "            \n",
    "        # fix missing value in Engin Fuel Type    \n",
    "        for f in df[fuel_ix]:\n",
    "            if pd.isnull(f):\n",
    "                new_fuel.append(\"regular unleaded\")\n",
    "            else:\n",
    "                new_fuel.append(f)\n",
    "                \n",
    "        df_upp = df[df[year_ix] >= 2010].copy()\n",
    "        df_low = df[df[year_ix] < 2010].copy()\n",
    "        \n",
    "        df = pd.concat([df_upp, df_low], axis=0)\n",
    "        df.reset_index(drop=True, inplace=True)\n",
    "        \n",
    "        df.drop([year_ix, fuel_ix, trans_ix], axis=1, inplace=True)\n",
    "\n",
    "        # add Engine Fuel Type column value fix\n",
    "        df.insert(0, 0, new_fuel)\n",
    "\n",
    "        # add Transmission column value fix\n",
    "        df.insert(1, 1, new_transmision)\n",
    "        \n",
    "        return df.values\n",
    "\n",
    "# for set y rows on other columns\n",
    "def y_set(df):\n",
    "    df_y_upp = df[df[\"Year\"] >= 2010].copy()\n",
    "    df_y_low = df[df[\"Year\"] < 2010].copy()\n",
    "\n",
    "    df_y = pd.concat([df_y_upp, df_y_low], axis=0)\n",
    "    df_y.reset_index(drop=True, inplace=True)\n",
    "    return df_y[\"MSRP\"]\n",
    "        \n",
    "# create df and y column\n",
    "df = train.copy()\n",
    "df_y = y_set(df)\n",
    "     \n",
    "attr_num = [\"Year\", \"Engine HP\", \"Engine Cylinders\", \"Number of Doors\", \"highway MPG\", \"city mpg\", \"Popularity\"]\n",
    "attr_cat = [\"Year\", \"Engine Fuel Type\", \"Transmission Type\", \"Driven_Wheels\", \"Vehicle Size\", \"Vehicle Style\"]\n",
    "\n",
    "# number preprocess\n",
    "num_pipeline = Pipeline([\n",
    "    (\"Attribute-selector\", AttributeSelector(attributes=attr_num)),\n",
    "    (\"EnginHp-fix\", EnginHpFix()),\n",
    "    (\"Simple-Imputer\", SimpleImputer(missing_values=np.nan, strategy='median')),\n",
    "    (\"Standard-scaler\", StandardScaler())\n",
    "])\n",
    "\n",
    "# category preprocess\n",
    "cat_pipeline = Pipeline([\n",
    "    (\"Attribute-selector\", AttributeSelector(attributes=attr_cat)),\n",
    "    (\"value_fix\", CategoryValueFix()),\n",
    "    (\"Ordinal-Encoder\", OrdinalEncoder(handle_unknown='error')),\n",
    "    (\"Standard-scaler\", StandardScaler())\n",
    "])\n",
    "\n",
    "final_pipeline = FeatureUnion(transformer_list=[\n",
    "    (\"number_operation\", num_pipeline),\n",
    "    (\"category_operation\", cat_pipeline)\n",
    "])\n",
    "\n",
    "df_prepared_tmp = final_pipeline.fit_transform(df)\n",
    "df_prepared = pd.DataFrame(df_prepared_tmp)\n",
    "\n",
    "df_prepared.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d751132",
   "metadata": {},
   "source": [
    "# test models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "928d7859",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for better show result in models\n",
    "def display_score(score, model):\n",
    "    print(\"===================\", model, \"===================\")\n",
    "    print(\"Your error = \", score)\n",
    "    print(\"mean = \", score.mean())\n",
    "    print(\"standard deviation = \", score.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f5f715e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dicision Tree\n",
    "dec_tree = DecisionTreeRegressor()\n",
    "dec_tree.fit(df_prepared, df_y)\n",
    "\n",
    "dec_predict = dec_tree.predict(df_prepared)\n",
    "mse = mean_squared_error(dec_predict, df_y)\n",
    "rmse = np.sqrt(mse)\n",
    "rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38ff0589",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest Regresion\n",
    "rand_forest = RandomForestRegressor()\n",
    "\n",
    "score = cross_val_score(rand_forest, df_prepared, df_y, scoring='neg_mean_squared_error', cv=10)\n",
    "score_rmse = np.sqrt(-score)\n",
    "\n",
    "display_score(score_rmse, \"Random Forest Regressor\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51fc73c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decision Tree On cross validation\n",
    "dec_reg = DecisionTreeRegressor()\n",
    "\n",
    "score = cross_val_score(dec_reg, df_prepared, df_y, scoring='neg_mean_squared_error', cv=10)\n",
    "score_rmse = np.sqrt(-score)\n",
    "\n",
    "display_score(score_rmse, \"Decision Tree Regressor\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3fd4625",
   "metadata": {},
   "outputs": [],
   "source": [
    "# XGboost Regression model \n",
    "xgb = XGBRegressor()\n",
    "\n",
    "score = cross_val_score(xgb, df_prepared, df_y, scoring='neg_mean_squared_error', cv=10)\n",
    "rmse_score = np.sqrt(-score)\n",
    "\n",
    "display_score(rmse_score, \"XGB Regressor\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe2f44e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# search best parametrs for xgboost regressor\n",
    "xbg = XGBRegressor()\n",
    "\n",
    "params = {\"n_estimators\": [200, 300, 400, 500], \"max_depth\": [3, 5, 7, 9]}\n",
    "xgb_gd_search = GridSearchCV(xgb, params, scoring='neg_mean_squared_error', cv=10)\n",
    "xgb_gd_search.fit(df_prepared, df_y)\n",
    "\n",
    "print(\"best params\", xgb_gd_search.best_params_)\n",
    "print(\"Best Estimator = \", xgb_gd_search.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afa7e06f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rand_forest = RandomForestRegressor()\n",
    "\n",
    "# params = {\"n_estimators\": [100, 200, 300, 400], \"max_features\": [4, 6, 8, 12]}\n",
    "# gd_search = GridSearchCV(rand_forest, params, scoring='neg_mean_squared_error', cv=10)\n",
    "# gd_search.fit(df_prepared, df_y)\n",
    "\n",
    "# print(\"best params\", gd_search.best_params_)\n",
    "# print(\"Best Estimator = \", gd_search.best_estimator_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6ed2f4d",
   "metadata": {},
   "source": [
    "# test process "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04ebafe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RandomForestRegressor(n_estimators=200)\n",
    "model.fit(df_prepared, df_y)\n",
    "\n",
    "# create test df\n",
    "test_df = test.copy()\n",
    "\n",
    "test_y = y_set(test_df)\n",
    "\n",
    "# preprocessing test df\n",
    "test_prepared = final_pipeline.transform(test_df)\n",
    "# predict values\n",
    "test_predict = model.predict(test_prepared)\n",
    "# mean score\n",
    "mse_test = mean_squared_error(test_y, test_predict)\n",
    "rmse_test = np.sqrt(mse_test)\n",
    "rmse_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3398849",
   "metadata": {},
   "source": [
    "# final class for py file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "594ba271",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "# Attribute Selectortegy\n",
    "class AttributeSelector(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, attributes):\n",
    "        self.attr_name = attributes\n",
    "        \n",
    "    def fit(self, df):\n",
    "        return self\n",
    "    \n",
    "    # return values for next process in pipeline\n",
    "    def transform(self, df):\n",
    "        return df[self.attr_name].values\n",
    "\n",
    "# hourse power missing value fix over year\n",
    "class EnginHpFix(BaseEstimator, TransformerMixin):\n",
    "    def fit(self, df):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, df):\n",
    "        year_ix, hp_ix = 0, 1        # Engine HP missing value fix over year\n",
    "        df = pd.DataFrame(df)\n",
    "        imputer = SimpleImputer(missing_values=np.nan, strategy='median')  \n",
    "        \n",
    "        df_hp_imputed_upp = imputer.fit_transform(df[df[year_ix] >= 2010][[hp_ix]])\n",
    "        df_hp_imputed_upp = pd.DataFrame(df_hp_imputed_upp)\n",
    "        df_hp_imputed_low = imputer.fit_transform(df[df[year_ix] < 2010][[hp_ix]])\n",
    "        df_hp_imputed_low = pd.DataFrame(df_hp_imputed_low)\n",
    "        df_hp_imputed = pd.concat([df_hp_imputed_upp, df_hp_imputed_low], axis=0)\n",
    "        df_hp_imputed.reset_index(drop=True, inplace=True)\n",
    "\n",
    "        # set all rows in Engin HP\n",
    "        df_num_upp = df[df[year_ix] >= 2010].copy()\n",
    "        df_num_low = df[df[year_ix] < 2010].copy()\n",
    "        df_num = pd.concat([df_num_upp, df_num_low], axis=0)\n",
    "        df_num.reset_index(drop=True, inplace=True)\n",
    "\n",
    "        # concatinate Engin Hp to numeric values\n",
    "        df_num.drop(hp_ix, axis=1, inplace=True)\n",
    "        df_num = pd.concat([df_num, df_hp_imputed], axis=1)\n",
    "        \n",
    "        return df_num.values\n",
    "    \n",
    "# Category value fix\n",
    "class CategoryValueFix(BaseEstimator, TransformerMixin):\n",
    "    def fit(self, df):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, df):\n",
    "        year_ix, fuel_ix, trans_ix = 0, 1, 2     # index column number\n",
    "        \n",
    "        # set rows in numeric values\n",
    "        df = pd.DataFrame(df)\n",
    "\n",
    "        # save fix value\n",
    "        new_transmision = []\n",
    "        new_fuel = []\n",
    "        \n",
    "        # fix Transmission Unknown Value\n",
    "        for t, y in zip(df[trans_ix], df[year_ix]):\n",
    "            if t == \"UNKNOWN\":\n",
    "                if y >= 2000:\n",
    "                    new_transmision.append(\"AUTOMATIC\")\n",
    "                else:\n",
    "                    new_transmision.append(\"MANUAL\")\n",
    "            else:\n",
    "                new_transmision.append(t)\n",
    "            \n",
    "        # fix missing value in Engin Fuel Type    \n",
    "        for f in df[fuel_ix]:\n",
    "            if pd.isnull(f):\n",
    "                new_fuel.append(\"regular unleaded\")\n",
    "            else:\n",
    "                new_fuel.append(f)\n",
    "                \n",
    "        df_upp = df[df[year_ix] >= 2010].copy()\n",
    "        df_low = df[df[year_ix] < 2010].copy()\n",
    "        \n",
    "        df = pd.concat([df_upp, df_low], axis=0)\n",
    "        df.reset_index(drop=True, inplace=True)\n",
    "        \n",
    "        df.drop([year_ix, fuel_ix, trans_ix], axis=1, inplace=True)\n",
    "\n",
    "        # add Engine Fuel Type column value fix\n",
    "        df.insert(0, 0, new_fuel)\n",
    "\n",
    "        # add Transmission column value fix\n",
    "        df.insert(1, 1, new_transmision)\n",
    "        \n",
    "        return df.values\n",
    "\n",
    "class DataMining(TransformerMixin, BaseEstimator):\n",
    "    __model = None\n",
    "    __base_value = None\n",
    "    __base_cars = None\n",
    "    \n",
    "    # for set y rows on other columns\n",
    "    def y_set(self, df):\n",
    "        df_y_upp = df[df[\"Year\"] >= 2010].copy()\n",
    "        df_y_low = df[df[\"Year\"] < 2010].copy()\n",
    "\n",
    "        df_y = pd.concat([df_y_upp, df_y_low], axis=0)\n",
    "        df_y.reset_index(drop=True, inplace=True)\n",
    "        return df_y[\"MSRP\"]\n",
    "    \n",
    "    # preproccessing operation\n",
    "    def preprocessing(self, df):\n",
    "        attr_num = [\"Year\", \"Engine HP\", \"Engine Cylinders\", \"Number of Doors\", \"highway MPG\", \"city mpg\", \"Popularity\"]\n",
    "        attr_cat = [\"Year\", \"Engine Fuel Type\", \"Transmission Type\", \"Driven_Wheels\", \"Vehicle Size\", \"Vehicle Style\"]\n",
    "\n",
    "        # number preprocess\n",
    "        num_pipeline = Pipeline([\n",
    "            (\"Attribute-selector\", AttributeSelector(attributes=attr_num)),\n",
    "            (\"EnginHp-fix\", EnginHpFix()),\n",
    "            (\"Simple-Imputer\", SimpleImputer(missing_values=np.nan, strategy='median')),\n",
    "            (\"Standard-scaler\", StandardScaler())\n",
    "        ])\n",
    "\n",
    "        # category preprocess\n",
    "        cat_pipeline = Pipeline([\n",
    "            (\"Attribute-selector\", AttributeSelector(attributes=attr_cat)),\n",
    "            (\"value_fix\", CategoryValueFix()),\n",
    "            (\"Ordinal-Encoder\", OrdinalEncoder(handle_unknown='error')),\n",
    "            (\"Standard-scaler\", StandardScaler())\n",
    "        ])\n",
    "\n",
    "        final_pipeline = FeatureUnion(transformer_list=[\n",
    "            (\"number_operation\", num_pipeline),\n",
    "            (\"category_operation\", cat_pipeline)\n",
    "        ])\n",
    "        \n",
    "        df_prepared = final_pipeline.fit_transform(df)\n",
    "        df_prepared = pd.DataFrame(df_prepared)\n",
    "        \n",
    "        return df_prepared\n",
    "    \n",
    "    def fit(self, df):\n",
    "        global cars\n",
    "        cars = pd.read_csv('D:/Code File\\Project/Car_F_and_P/Car F and P.csv')\n",
    "        train, te = train_test_split(cars, train_size=0.8, random_state=2)\n",
    "        \n",
    "        # preproccessing firs data and new data \n",
    "        cars_prepared = self.preprocessing(train)\n",
    "        \n",
    "        # set y first data for learn michin\n",
    "        cars_y = self.y_set(train)\n",
    "        \n",
    "        # learn model\n",
    "        rand_forest = RandomForestRegressor(n_estimators=200)\n",
    "        rand_forest.fit(cars_prepared, cars_y)\n",
    "        \n",
    "        self.__model = rand_forest     # save model for use in transform\n",
    "        \n",
    "        return self\n",
    "        \n",
    "    # use new data frame and result\n",
    "    def transform(self, df):\n",
    "        # Both for small data and for accurate prediction\n",
    "        base = cars\n",
    "        base[\"find\"] = False\n",
    "        df[\"find\"] = True\n",
    "        \n",
    "        df = pd.concat([base, df], axis=0)\n",
    "        \n",
    "        # set base value in price predict\n",
    "        value_upp = df[df[\"Year\"] >= 2010].copy()\n",
    "        value_low = df[df[\"Year\"] < 2010].copy()\n",
    "\n",
    "        df_set = pd.concat([value_upp, value_low], axis=0)\n",
    "        df_set.reset_index(drop=True, inplace=True)\n",
    "        find_ix = df_set[df_set[\"find\"] == True].index\n",
    "        \n",
    "        # save value \n",
    "        df_set.drop(\"find\", axis=1, inplace=True)\n",
    "        self.__base_value = df_set.loc[find_ix]\n",
    "        self.__base_value.reset_index(drop=True, inplace=True)\n",
    "\n",
    "        df_x = self.preprocessing(df)\n",
    "        df_x = df_x.loc[find_ix]\n",
    "        \n",
    "        model = self.__model\n",
    "        \n",
    "        # predict price\n",
    "        df_y = model.predict(df_x)\n",
    "        df_y = pd.DataFrame(df_y, columns=[\"Price\"])\n",
    "        \n",
    "        # final data frame\n",
    "        df_predicted = pd.concat([self.__base_value, df_y], axis=1)\n",
    "        \n",
    "        return df_predicted\n",
    "    \n",
    "    \n",
    "testes = pd.read_csv(\"Car F and P Test.csv\")\n",
    "testes = testes[3000:3001]\n",
    "dm = DataMining()\n",
    "t_pred = dm.fit_transform(testes)\n",
    "t_pred.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
